{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b28e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from model_util import DeepModel\n",
    "from multi import ImageSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1512d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    def __init__(self):\n",
    "        self.all_skus = {}\n",
    "        self.model = DeepModel()\n",
    "        self.predict_time = 0\n",
    "        self.time_search = 0\n",
    "        self.count_frame = 0\n",
    "        self.top_k = 5\n",
    "\n",
    "    def extract_features_from_img(self, cur_img):\n",
    "        \"\"\"Судя по названию эта функция извлекает фичи из тестового изображения\"\"\"\n",
    "        cur_img = cv2.resize(cur_img, (224, 224))\n",
    "        img = preprocess_input(cur_img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        feature = self.model.extract_feature(img)\n",
    "        return feature\n",
    "\n",
    "    def predict(self, img):\n",
    "        self.count_frame += 1\n",
    "        before_time = time.time()\n",
    "        target_features = self.extract_features_from_img(img)\n",
    "        self.predict_time += time.time() - before_time\n",
    "        max_distance = 0\n",
    "        result_dish = 0\n",
    "\n",
    "        for dish, features_all in self.all_skus.items():\n",
    "            for features in features_all:\n",
    "                cur_distance = self.model.cosine_distance(target_features, features)\n",
    "                cur_distance = cur_distance[0][0]\n",
    "                if cur_distance > max_distance:\n",
    "                    max_distance = cur_distance\n",
    "                    result_dish = dish\n",
    "\n",
    "        return result_dish, max_distance\n",
    "\n",
    "    def add_img(self, img_path, id_img):\n",
    "        img = cv2.imread(img_path)\n",
    "        cur_img = img\n",
    "        feature = self.extract_features_from_img(cur_img)\n",
    "        if id_img not in self.all_skus:\n",
    "            self.all_skus[id_img] = []\n",
    "        self.all_skus[id_img].append(feature)\n",
    "        return feature\n",
    "\n",
    "    def remove_by_id(self, id_img):\n",
    "        if id_img in self.all_skus:\n",
    "            self.all_skus.pop(id_img)\n",
    "\n",
    "    def remove_all(self):\n",
    "        self.all_skus.clear()\n",
    "\n",
    "    def add_img_from_pickle(self, id_img, pickle_path):\n",
    "        res = pickle.load(open(pickle_path, 'rb'))\n",
    "        self.all_skus[id_img] = res\n",
    "\n",
    "    def get_additional_info(self):\n",
    "        json_res = {}\n",
    "        json_res[\"Extract features, time\"] = self.predict_time\n",
    "        json_res[\"Find nearest, time\"] = self.time_search\n",
    "        json_res[\"Count frame\"] = self.count_frame\n",
    "        json_res[\"RPS\"] = self.count_frame / (self.predict_time + self.time_search)\n",
    "        return json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eeede07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\omelchenko\\Documents\\GitHub\\image_classifaier\\model_util.py:38: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Loading MobileNet.\n",
      "\n",
      "Loading MobileNet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"тут немножко парсим аргументы изображения путь которому передаётся через командную строку. Создаётся объект,\n",
    "    устанавливаются флаги для передачи изображения, создаётся переменная с аргументами, читается изображение \n",
    "    и аргумент image кладётся в переменную с таким же названием.\"\"\"\n",
    "#     ap = argparse.ArgumentParser()\n",
    "#     ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
    "#     args = vars(ap.parse_args())\n",
    "\n",
    "#     image = cv2.imread(args[\"image\"])\n",
    "    \n",
    "    \"\"\"загрузим и обработаем входящее изображение и изображения с которыми сравниваем\"\"\"\n",
    "#     image = cv2.imread('Odata/red_h.jpg')\n",
    "    inp_classifaier = ImageClassifier()\n",
    "    d_imgs = \"Odata\"\n",
    "    d_path = os.listdir(d_imgs)\n",
    "    \n",
    "    for f in d_path:\n",
    "        inp_classifaier.add_img(os.path.join(d_imgs, f), f)\n",
    "    \n",
    "    inp_classifaier_all_skus_list = list(inp_classifaier.__dict__['all_skus'].keys())\n",
    "    test1 = np.array(inp_classifaier.__dict__['all_skus'][str(inp_classifaier_all_skus_list[0])][0])\n",
    "    np.savetxt(\"Odata/test1.csv\", test1, delimiter=',')\n",
    "    \n",
    "    \n",
    "    classifier = ImageClassifier()\n",
    "    t_imgs = \"Otest\"\n",
    "    t_paths = os.listdir(t_imgs)\n",
    "    \n",
    "    for f in t_paths:\n",
    "        classifier.add_img(os.path.join(t_imgs, f), f)\n",
    "    \n",
    "    classifaier_all_skus_list = list(classifier.__dict__['all_skus'].keys())\n",
    "    test2 = np.array(classifier.__dict__['all_skus'][str(classifaier_all_skus_list[0])][0])\n",
    "    np.savetxt(\"Otest/test2.csv\", test2, delimiter=',')\n",
    "    \n",
    "    print(inp_classifaier_all_skus_list, '/n')\n",
    "    print(classifaier_all_skus_list)\n",
    "    \n",
    "    \n",
    "#     \"\"\"Создаём объект сравнения\"\"\"\n",
    "#     similarity = ImageSimilarity()\n",
    "    \n",
    "#     '''Setup'''\n",
    "#     similarity.batch_size = 16\n",
    "#     similarity.num_processes = 2\n",
    "    \n",
    "#     '''Load source data'''\n",
    "#     test1_sim = similarity.load_data_csv('Odata/test1.csv', delimiter=',')\n",
    "#     test2_sim = similarity.load_data_csv('Otest/test2.csv', delimiter=',')#, cols=['id', 'url'])\n",
    "\n",
    "#     '''Save features and fields'''\n",
    "#     similarity.save_data('test1', test1)\n",
    "#     similarity.save_data('test2', test2)\n",
    "\n",
    "#     '''Calculate similarities'''\n",
    "#     result = similarity.iteration(['test1_id', 'test1_url', 'test2_id', 'test2_url'], thresh=0.845)\n",
    "#     print('Row for source file 1, and column for source file 2.')\n",
    "#     print(result)\n",
    "        \n",
    "#     print(classifier.__dict__)\n",
    "#     print(in_classifaier.__dict__)\n",
    "#     cv2.imshow(\"Image\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6757a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omelchenko\\Documents\\GitHub\\image_classifaier\\multi.py:144: UserWarning: genfromtxt: Empty input file: \"Odata/test1.csv\"\n",
      "  data = np.genfromtxt(\n",
      "C:\\Users\\omelchenko\\Documents\\GitHub\\image_classifaier\\multi.py:144: UserWarning: genfromtxt: Empty input file: \"Otest/test2.csv\"\n",
      "  data = np.genfromtxt(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileNet.\n",
      "\n",
      "test1: download starts.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m test2_sim \u001b[38;5;241m=\u001b[39m similarity\u001b[38;5;241m.\u001b[39mload_data_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOtest/test2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#, cols=['id', 'url'])\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m'''Save features and fields'''\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43msimilarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest1_sim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m similarity\u001b[38;5;241m.\u001b[39msave_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest2\u001b[39m\u001b[38;5;124m'\u001b[39m, test2_sim)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m'''Calculate similarities'''\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\image_classifaier\\multi.py:190\u001b[0m, in \u001b[0;36mImageSimilarity.save_data\u001b[1;34m(self, title, lines)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: download starts.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m title)\n\u001b[0;32m    188\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 190\u001b[0m args \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: line[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m'\u001b[39m: line} \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[0;32m    193\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_generator(args)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\image_classifaier\\multi.py:190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: download starts.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m title)\n\u001b[0;32m    188\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 190\u001b[0m args \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m'\u001b[39m: line} \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[0;32m    193\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_generator(args)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\"\"\"Создаём объект сравнения\"\"\"\n",
    "similarity = ImageSimilarity()\n",
    "\n",
    "'''Setup'''\n",
    "similarity.batch_size = 16\n",
    "similarity.num_processes = 2\n",
    "\n",
    "'''Load source data'''\n",
    "test1_sim = similarity.load_data_csv('Odata/test1.csv', delimiter=',')\n",
    "test2_sim = similarity.load_data_csv('Otest/test2.csv', delimiter=',')#, cols=['id', 'url'])\n",
    "\n",
    "'''Save features and fields'''\n",
    "similarity.save_data('test1', test1_sim)\n",
    "similarity.save_data('test2', test2_sim)\n",
    "\n",
    "'''Calculate similarities'''\n",
    "result = similarity.iteration(['test1_id', 'test1_url', 'test2_id', 'test2_url'], thresh=0.845)\n",
    "print('Row for source file 1, and column for source file 2.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_classifaier.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d19a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_classifaier.__dict__['all_skus'][str(inp_classifaier_all_skus_list[0])][0]#['t_img.jpg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef862aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_classifaier_all_skus_list = list(inp_classifaier.__dict__['all_skus'].keys())\n",
    "print(inp_classifaier_all_skus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in classifier.__dict__['all_skus'].items():\n",
    "    print(k, '------>', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5112e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i classifier.__dict__['all_skus']['santahat.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61def3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_classifaier.__dict__['all_skus']['t_img.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e8fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
