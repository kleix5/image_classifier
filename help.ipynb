{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b28e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from model_util import DeepModel\n",
    "from multi import ImageSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1512d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    def __init__(self):\n",
    "        self.all_skus = {}\n",
    "        self.model = DeepModel()\n",
    "        self.predict_time = 0\n",
    "        self.time_search = 0\n",
    "        self.count_frame = 0\n",
    "        self.top_k = 5\n",
    "\n",
    "    def extract_features_from_img(self, cur_img):\n",
    "        \"\"\"Судя по названию эта функция извлекает фичи из тестового изображения\"\"\"\n",
    "        cur_img = cv2.resize(cur_img, (224, 224))\n",
    "        img = preprocess_input(cur_img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        feature = self.model.extract_feature(img)\n",
    "        return feature\n",
    "\n",
    "    def predict(self, img):\n",
    "        self.count_frame += 1\n",
    "        before_time = time.time()\n",
    "        target_features = self.extract_features_from_img(img)\n",
    "        self.predict_time += time.time() - before_time\n",
    "        max_distance = 0\n",
    "        result_dish = 0\n",
    "\n",
    "        for dish, features_all in self.all_skus.items():\n",
    "            for features in features_all:\n",
    "                cur_distance = self.model.cosine_distance(target_features, features)\n",
    "                cur_distance = cur_distance[0][0]\n",
    "                if cur_distance > max_distance:\n",
    "                    max_distance = cur_distance\n",
    "                    result_dish = dish\n",
    "\n",
    "        return result_dish, max_distance\n",
    "\n",
    "    def add_img(self, img_path, id_img):\n",
    "        img = cv2.imread(img_path)\n",
    "        cur_img = img\n",
    "        feature = self.extract_features_from_img(cur_img)\n",
    "        if id_img not in self.all_skus:\n",
    "            self.all_skus[id_img] = []\n",
    "        self.all_skus[id_img].append(feature)\n",
    "        return feature\n",
    "\n",
    "    def remove_by_id(self, id_img):\n",
    "        if id_img in self.all_skus:\n",
    "            self.all_skus.pop(id_img)\n",
    "\n",
    "    def remove_all(self):\n",
    "        self.all_skus.clear()\n",
    "\n",
    "    def add_img_from_pickle(self, id_img, pickle_path):\n",
    "        res = pickle.load(open(pickle_path, 'rb'))\n",
    "        self.all_skus[id_img] = res\n",
    "\n",
    "    def get_additional_info(self):\n",
    "        json_res = {}\n",
    "        json_res[\"Extract features, time\"] = self.predict_time\n",
    "        json_res[\"Find nearest, time\"] = self.time_search\n",
    "        json_res[\"Count frame\"] = self.count_frame\n",
    "        json_res[\"RPS\"] = self.count_frame / (self.predict_time + self.time_search)\n",
    "        return json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eeede07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\py_projects\\imgcls\\model_util.py:38: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Loading MobileNet.\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m d_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(d_imgs)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m d_path:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43min_classifaier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m test1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(in_classifaier\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_skus\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_img.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     21\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOdata/test1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, test1, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m, in \u001b[0;36mImageClassifier.add_img\u001b[1;34m(self, img_path, id_img)\u001b[0m\n\u001b[0;32m     37\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m     38\u001b[0m cur_img \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m---> 39\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features_from_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m id_img \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_skus:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_skus[id_img] \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m, in \u001b[0;36mImageClassifier.extract_features_from_img\u001b[1;34m(self, cur_img)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features_from_img\u001b[39m(\u001b[38;5;28mself\u001b[39m, cur_img):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Судя по названию эта функция извлекает фичи из тестового изображения\"\"\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     cur_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     img \u001b[38;5;241m=\u001b[39m preprocess_input(cur_img)\n\u001b[0;32m     14\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"тут немножко парсим аргументы изображения путь которому передаётся через командную строку. Создаётся объект,\n",
    "    устанавливаются флаги для передачи изображения, создаётся переменная с аргументами, читается изображение \n",
    "    и аргумент image кладётся в переменную с таким же названием.\"\"\"\n",
    "#     ap = argparse.ArgumentParser()\n",
    "#     ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
    "#     args = vars(ap.parse_args())\n",
    "\n",
    "#     image = cv2.imread(args[\"image\"])\n",
    "    \n",
    "    \"\"\"загрузим и обработаем входящее изображение и изображения с которыми сравниваем\"\"\"\n",
    "#     image = cv2.imread('Odata/red_h.jpg')\n",
    "    in_classifaier = ImageClassifier()\n",
    "    d_imgs = \"Odata\"\n",
    "    d_path = os.listdir(d_imgs)\n",
    "    \n",
    "    for f in d_path:\n",
    "        in_classifaier.add_img(os.path.join(d_imgs, f), f)\n",
    "    \n",
    "    test1 = np.array(in_classifaier.__dict__['all_skus']['t_img.jpg'][0])\n",
    "    np.savetxt(\"Odata/test1.csv\", test1, delimiter=',')\n",
    "    \n",
    "    \n",
    "    classifier = ImageClassifier()\n",
    "    t_imgs = \"Otest\"\n",
    "    t_paths = os.listdir(t_imgs)\n",
    "    \n",
    "    for f in t_paths:\n",
    "        classifier.add_img(os.path.join(t_imgs, f), f)\n",
    "    \n",
    "    test2 = np.array(in_classifaier.__dict__['all_skus']['santahat.jpg'][0])\n",
    "    np.savetxt(\"Otest/test2.csv\", test2, delimiter=',')\n",
    "    \n",
    "    \"\"\"Создаём объект сравнения\"\"\"\n",
    "    similarity = ImageSimilarity()\n",
    "    \n",
    "    '''Setup'''\n",
    "    similarity.batch_size = 16\n",
    "    similarity.num_processes = 2\n",
    "    \n",
    "    '''Load source data'''\n",
    "    test1_sim = similarity.load_data_csv('Odata/test1.csv', delimiter=',')\n",
    "    test2_sim = similarity.load_data_csv('Otest/test2.csv', delimiter=',')#, cols=['id', 'url'])\n",
    "\n",
    "    '''Save features and fields'''\n",
    "    similarity.save_data('test1', test1)\n",
    "    similarity.save_data('test2', test2)\n",
    "\n",
    "    '''Calculate similarities'''\n",
    "    result = similarity.iteration(['test1_id', 'test1_url', 'test2_id', 'test2_url'], thresh=0.845)\n",
    "    print('Row for source file 1, and column for source file 2.')\n",
    "    print(result)\n",
    "        \n",
    "#     print(classifier.__dict__)\n",
    "#     print(in_classifaier.__dict__)\n",
    "#     cv2.imshow(\"Image\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d19a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_classifaier.__dict__['all_skus']['t_img.jpg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in classifier.__dict__['all_skus'].items():\n",
    "    print(k, '------>', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5112e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i classifier.__dict__['all_skus']['santahat.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61def3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_classifaier.__dict__['all_skus']['t_img.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e8fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
